{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c1199c",
   "metadata": {},
   "source": [
    "This noteboook uses the slab2 model data, available to download from https://www.sciencebase.gov/catalog/item/5aa1b00ee4b0b1c392e86467, and formats it into an ascii data boundary for an input in Aspect.\n",
    "Run this notebook in the \"Slab2_TXT\" folder inside the parent directory of slab2 model or alternatively change \n",
    "the working directory of the notebook.\n",
    "\n",
    "Input files: Each input file contains attributes representing either depth \n",
    "             \"dep\", dip (\"dip\"), strike (\"str\"), and thickness (\"thk\") information for each of the 27 slabs in the                slab2 model in a structured ascii grid. The files contains columns corresponding to longitude,                      latitude, and attribute (\"dep, \"dip\" etc). More information on the model can be found in the paper:                  Hayes, G. P., Moore, G. L., Portner, D. E., Hearne, M., Flamme, H., Furtney, M., & Smoczyk, G. M.                    (2018). Slab2,a comprehensive subduction zone geometry model. Science, 362(6410), 58-61.\n",
    "\n",
    "Output     : A structured file containing all the slabs for the Earth with columns representing longitude,       colatitude, slab depths, and slab thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7a1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951e547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current working directory\n",
    "cwd = os.getcwd()\n",
    "# Set the path to the downloaded slab2 model here.\n",
    "os.chdir('/home/postdoc/Downloads/Slab2_AComprehe/Slab2Distribute_Mar2018/Slab2_TXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ecd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_data (name_key, type_key):\n",
    "    \"\"\"\n",
    "    From initial data inspection, we found that most slabs have spacing of 0.05 degrees except for 5 slabs,   \n",
    "    which have 0.02 degree spacing. Therefore, this function interpolates those slabs to 0.05 spacing for \n",
    "    consistency.\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = glob(name_key + '*' + type_key +'*.xyz')\n",
    "    data_in   = np.loadtxt (file_name[0], delimiter=\",\")\n",
    "    \n",
    "    # We convert latitudes to co-latitudes for all the slab files.\n",
    "    points_x  = data_in[:, 0] \n",
    "    points_y  = 90 - data_in[:, 1]\n",
    "    field     = data_in[:, 2]\n",
    "    \n",
    "    x0 = np.min(points_x)\n",
    "    x1 = np.max(points_x)\n",
    "    y0 = np.min(points_y)\n",
    "    y1 = np.max(points_y)\n",
    "    \n",
    "    # create the desired mesh\n",
    "    x = np.arange (x0, x1 + 0.05, 0.05)\n",
    "    y = np.arange (y0, y1 + 0.05, 0.05)\n",
    "    \n",
    "    x_grid, y_grid = np.meshgrid (x, y)\n",
    "    \n",
    "    depth_interp = griddata ((points_x, points_y), field, (x_grid, y_grid), method = 'linear')\n",
    "    data_save    = np.column_stack ((x_grid.flatten(), 90 - y_grid.flatten(), depth_interp.flatten()))\n",
    "    \n",
    "    np.savetxt (file_name[0], data_save, fmt='%1.2f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae1608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slabs with 0.02 spacing\n",
    "file_name_key = ['hin', 'man', 'mue', 'pam', 'puy']\n",
    "file_type_key = ['dep', 'thk']\n",
    "\n",
    "for i in range(len(file_name_key)): \n",
    "    interpolate_data (file_name_key[i], 'dep')\n",
    "    interpolate_data (file_name_key[i], 'thk')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b61a9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid for aspect, with global longitudes and colatitudes and\n",
    "# resolution same as all the slabs (0.05 degrees)\n",
    "# We initialize the depth and thickness arrays with a very large number \n",
    "# so that in aspect an if condition can be used for regions where values\n",
    "# do not exist.\n",
    "longitudes_target = np.arange (0 , 360.05, 0.05)\n",
    "latitudes_target  = np.arange (0,  180.05, 0.05)\n",
    "longitude_grid, latitude_grid = np.meshgrid (longitudes_target, latitudes_target)\n",
    "\n",
    "depths_target       = 1e10 * np.ones (len(longitude_grid.flatten()),)\n",
    "thickness_target    = 1e10 * np.ones (len(longitude_grid.flatten()),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa3f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indx = 0 \n",
    "def slab2_into_asciiboundary (slab_filename):\n",
    "    \"\"\"\n",
    "    This function uses the above target mesh and fills it with the input slab depths and thicknesses. \n",
    "    Since the input data grid for each slab is a subset of this target grid, we can simply replace \n",
    "    the target grid at those locations with the input slab grid. \n",
    "    We have checked that in the input files longitude increases first and then latitude, suggesting that the \n",
    "    elements are ordered similarly with the target mesh.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the input slab depth files\n",
    "    slab_data = np.loadtxt (slab_filename, delimiter=\",\")\n",
    "    points_x  = slab_data[:, 0] \n",
    "    points_y  = 90 - slab_data[:, 1]\n",
    "    depths    = slab_data[:, 2]    \n",
    "    \n",
    "    x0 = np.min(points_x)\n",
    "    x1 = np.max(points_x)\n",
    "    y0 = np.min(points_y)\n",
    "    y1 = np.max(points_y)\n",
    "    \n",
    "    # need this to compare two floats\n",
    "    numerical_error = 1e-6\n",
    "   \n",
    "    indx = np.where ( (longitude_grid.flatten() >= x0 - numerical_error) & \n",
    "                      (longitude_grid.flatten() <= x1 + numerical_error) &\n",
    "                      (latitude_grid.flatten()  >= y0 - numerical_error) & \n",
    "                      (latitude_grid.flatten()  <= y1 + numerical_error) )\n",
    "    \n",
    "    # We do not simply replace all the points with the slab grid. This is because there \n",
    "    # are some slabs in the western US with overlapping grid points. However, locations \n",
    "    # in the slab grid where depths and thickness are not defined are nan values, and we\n",
    "    # want to avoid replacing existing depth and thickness values with nan values \n",
    "    # from another slab grid.\n",
    "    # Therefore, we  create a dummy variable that stores all the grid points in the slab \n",
    "    # and then store only the non-nan values into the target array.\n",
    "    depths_temp       = np.empty (len(longitude_grid.flatten()),)  \n",
    "    depths_temp[:]    = np.nan\n",
    "    depths_temp[indx] = slab_data[:, 2]\n",
    "    \n",
    "    # replace the target mesh with the slab data\n",
    "    indx_not_a_nan                = np.where(~np.isnan (depths_temp))\n",
    "    depths_target[indx_not_a_nan] = depths_temp[indx_not_a_nan]\n",
    "    \n",
    "    # do the same for the thickness file\n",
    "    thk_file  = slab_filename.replace ('dep', 'thk')\n",
    "    thk_data  = np.loadtxt (thk_file, delimiter=\",\", usecols=2)\n",
    "    \n",
    "    # We checked that slab thickness is defined at points where\n",
    "    # slab depths are defined.\n",
    "    thickness_target[indx_not_a_nan] = thk_data[np.where(~np.isnan (depths))]\n",
    "\n",
    "    return (depths_target, thickness_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57ac1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hel_slab2_dep_02.24.18.xyz\n",
      "ryu_slab2_dep_02.26.18.xyz\n",
      "mak_slab2_dep_02.24.18.xyz\n",
      "van_slab2_dep_02.23.18.xyz\n",
      "mue_slab2_dep_02.24.18.xyz\n",
      "sum_slab2_dep_02.23.18.xyz\n",
      "png_slab2_dep_02.26.18.xyz\n",
      "pam_slab2_dep_02.26.18.xyz\n",
      "cal_slab2_dep_02.24.18.xyz\n",
      "cot_slab2_dep_02.24.18.xyz\n",
      "hal_slab2_dep_02.23.18.xyz\n",
      "sco_slab2_dep_02.23.18.xyz\n",
      "puy_slab2_dep_02.26.18.xyz\n",
      "car_slab2_dep_02.24.18.xyz\n",
      "phi_slab2_dep_02.26.18.xyz\n",
      "sul_slab2_dep_02.23.18.xyz\n",
      "hin_slab2_dep_02.24.18.xyz\n",
      "kur_slab2_dep_02.24.18.xyz\n",
      "cas_slab2_dep_02.24.18.xyz\n",
      "cam_slab2_dep_02.24.18.xyz\n",
      "alu_slab2_dep_02.23.18.xyz\n",
      "izu_slab2_dep_02.24.18.xyz\n",
      "sol_slab2_dep_02.23.18.xyz\n",
      "ker_slab2_dep_02.24.18.xyz\n",
      "man_slab2_dep_02.24.18.xyz\n",
      "him_slab2_dep_02.24.18.xyz\n",
      "sam_slab2_dep_02.23.18.xyz\n"
     ]
    }
   ],
   "source": [
    "input_filenames = glob('*_slab2*' + file_type_key[0]  + '*.xyz')\n",
    "\n",
    "for i in range(len(input_filenames)):\n",
    "    print (input_filenames[i])\n",
    "    slab_depths, slab_thickness = slab2_into_asciiboundary (input_filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4969684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the arrays in the format for aspect ascii boundary :\n",
    "# 1. use radians in longitudes and latitudes, 2. first longitudes increase then latitudes\n",
    "# 3. convert depth and thickness from km to meters 4. depth is negative in the downward\n",
    "# direction of the slab2 database, convert to positive values. 5. Add necessary header\n",
    "# information.\n",
    "\n",
    "output_dir       = cwd\n",
    "output_filename  = '/slab2_depth_thickness_2D.txt'\n",
    "output_data      = np.column_stack (( np.deg2rad(longitude_grid.flatten()), np.deg2rad(latitude_grid.flatten()),\n",
    "                                     abs(depths_target.flatten())*1e3, thickness_target.flatten()*1e3 ))\n",
    "\n",
    "aspect_header    = 'Test data for ascii data initial conditions.\\n'+ \\\n",
    "                   'Only next line is parsed in format: [nx] [ny] because of keyword \"POINTS\"\\n' + \\\n",
    "                   'POINTS: %d %d\\n' %(np.size(longitudes_target), np.size(latitudes_target)) + \\\n",
    "                   'Columns: phi theta depth(m) thickness(m)'\n",
    "\n",
    "np.savetxt (output_dir + output_filename, output_data, header=aspect_header, fmt='%.4e', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f2f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
